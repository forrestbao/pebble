{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching Tweets in Python \n",
    "\n",
    "## Copyleft 2020 Forrest Sheng Bao \n",
    "\n",
    "To get the code working, you need to get Twitter Developer Account. \n",
    "Then create a file `credentials.py` and put your Twitter API credentials in it, like this (the keys and secrete below do not work. Just examples): \n",
    "\n",
    "```\n",
    "consumer_key = \"xvz1evFS4wEEPTGEFPHBog\"\n",
    "consumer_secrete = \"L8qq9PZyRg6ieKGEKhZolGC0vJWLw8iEJ88DRdyOg\"\n",
    "bearer_token = \"AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\"  # This one is optional. And you won't have it until your finish step 1. \n",
    "```\n",
    "\n",
    "Opinions expressed here do not reflect those of Iowa State University and Iowa NPR. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Load libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import credentials # a user script containing keys, secrets, and tokens \n",
    "\n",
    "import json\n",
    "import base64\n",
    "import copy\n",
    "\n",
    "# use two (diversity!) libraries for making web requests\n",
    "import requests # for authentication\n",
    "import urllib   # for crawling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Get Twitter authentication \n",
    "\n",
    "We only need OAuth 2.0 Basic authentication because the script below only access public tweets. No need for OAuth 1.0 which accesses user-specific data. \n",
    "\n",
    "It will send a request to Twitter's server with your Twitter developer credentials (not your Twitter username and password). If correct, the server will return a Bearer access token. \n",
    "Include that token in the headers of all search queries in the future. \n",
    "\n",
    "If you have valid Bearer token, you can skip this step. \n",
    "The next step assumes Bearer token is saved in the `credential.py` file \n",
    "\n",
    "For more details: see \n",
    "https://developer.twitter.com/en/docs/basics/authentication/oauth-2-0/application-only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = credentials.consumer_key \n",
    "consumer_secrete = credentials.consumer_secrete\n",
    "\n",
    "bearer = \":\".join([consumer_key, consumer_secrete])\n",
    "bearer_base64 = str(base64.b64encode(bearer.encode('utf-8')))\n",
    "\n",
    "r = requests.post('https://api.twitter.com/oauth2/token',\n",
    "                   data={\"grant_type\":\"client_credentials\"},\n",
    "                   headers = {\"Authorization\": \"Basic \" + bearer_base64, \n",
    "                              \"Content-Type\": \"application/x-www-form-urlencoded;charset=UTF-8\"}\n",
    "                   )\n",
    "\n",
    "reply = json.loads(r.content)\n",
    "bearer_token = result['access_token']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Search tweets using tags\n",
    "\n",
    "Let's do a very basic search: find all Tweets of the tag `#coronavirus`. Note that Twitter's Free/Basic API only allows searching with in the past 7 days. \n",
    "\n",
    "Somehow Twitter's official API guide didn't mention how to include Bearer token in the search. \n",
    "So here is a side info\n",
    "https://stackoverflow.com/questions/53002662/get-user-information-in-twitter-api-using-bearer-token\n",
    "\n",
    "See more at: \n",
    "* https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets\n",
    "* https://developer.twitter.com/en/docs/tweets/search/guides/standard-operators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_search(bearer_token, search_url_base, tag, lang, result_type, count): \n",
    "    \"\"\"Basic search using tags \n",
    "\n",
    "    return all recent tweets of a tag, \n",
    "              in a specific language (e.g., 'en'), \n",
    "              in a result_type (mixed -- default, popular, recent), \n",
    "              for count (1 to 100, default 15) amount\n",
    "         as a list of dicts\n",
    "    \"\"\"\n",
    "    search_url = search_url_base + \"?q=\" +\\\n",
    "                 query_tag.replace(\"#\", \"%23\") + \"&\" +\\\n",
    "                 \"lang={}\".format(lang) + \"&\" +\\\n",
    "                 \"result_type={}\".format(result_type) + \"&\" +\\\n",
    "                 \"count={}\".format(count) + \"&\" + \\\n",
    "                 \"tweet_mode=extended\"\n",
    "\n",
    "    print (\"Searching URL...\", search_url)\n",
    "\n",
    "    request_headers = {\"Authorization\":\"Bearer \" + bearer_token}\n",
    "\n",
    "    request = urllib.request.Request(search_url, headers=request_headers)\n",
    "    reply = urllib.request.urlopen(request) \n",
    "    tweets = reply.read()\n",
    "    tweets = json.loads(tweets.decode('utf-8'))\n",
    "    \n",
    "    print (\"Done\")\n",
    "    return tweets['statuses']\n",
    "\n",
    "\n",
    "# To try it out, uncomment the lines below. \n",
    "# bearer_token = credentials.bearer_token\n",
    "# query_tag = \"#coronavirus\"\n",
    "# search_url_base = \"https://api.twitter.com/1.1/search/tweets.json\"\n",
    "# tweets = tag_search(bearer_token, search_url_base, query_tag, \"en\", \"popular\", \"5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter returns a very verbose information of the tweets. So you can distill down a little bit with certain information you care about. In the example below, we only keep information fields that are specified in a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distill_tweets(tweets, info_keys, show_url):\n",
    "    \"\"\"\n",
    "\n",
    "    tweets: a list of tweets as dicts, result of extended search. \n",
    "    Keys are: ['contributors', 'coordinates', 'created_at',\n",
    "               'display_text_range', 'entities', \n",
    "               'favorite_count', 'favorited', 'full_text', 'geo',\n",
    "               'id', 'id_str', 'in_reply_to_screen_name', 'in_reply_to_status_id', \n",
    "               'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str',\n",
    "               'is_quote_status', 'lang', 'metadata', \n",
    "               'place', 'possibly_sensitive',\n",
    "               'retweet_count','retweeted',\n",
    "               'source','truncated',  'user' ] # author\n",
    "\n",
    "    \"\"\"\n",
    "    counter  = 1 \n",
    "    new_tweets = []\n",
    "    for old_tweet in tweets: \n",
    "        new_tweet = {}\n",
    "        for key in info_keys:\n",
    "            if type(key) == str:\n",
    "                new_tweet[key] = old_tweet[key]\n",
    "            elif type(key) == list:\n",
    "                x = copy.deepcopy(old_tweet)\n",
    "                for i in key: \n",
    "                    x = x[i]\n",
    "                new_tweet[\"_\".join(key)] = x\n",
    "        new_tweets.append(new_tweet)\n",
    "        if show_url:\n",
    "            print (str(counter)+  \".\", end = \" \")\n",
    "            print (\"By\", new_tweet['user_screen_name'], \"at\", new_tweet[\"created_at\"])\n",
    "            print(\"https://twitter.com/i/web/status/\"+old_tweet['id_str'])\n",
    "            print (new_tweet['full_text'])\n",
    "            print ()\n",
    "        counter  += 1 \n",
    "    return new_tweets\n",
    "\n",
    "# To try it out, uncomment lines below\n",
    "# info_keys = [\"full_text\", \"created_at\", ['user','screen_name']]\n",
    "# new_tweets = distill_tweets(tweets, info_keys, True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Put everything together \n",
    "\n",
    "If you just want something that works with everything in default, edit the last line. Specify a hashtag and how many results you want in return. \n",
    "\n",
    "With free/basic Twitter API, you can search up to 450 times in a 15-minute window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching URL... https://api.twitter.com/1.1/search/tweets.json?q=%23coronavirus&lang=en&result_type=popular&count=15&tweet_mode=extended\n",
      "Done\n",
      "\n",
      "Search result:\n",
      "1. By abhijitmajumder at Sun Feb 16 04:14:53 +0000 2020\n",
      "https://twitter.com/i/web/status/1228895497923940352\n",
      "This is beyond eerie. A 1981 thriller by Dean Koontz predicted the #Coronavirus nightmare, pinpointing it to supposedly biological weapons labs in China‚Äôs Wuhan! https://t.co/LYIIdEnsEL\n",
      "\n",
      "2. By HawleyMO at Sun Feb 16 00:31:47 +0000 2020\n",
      "https://twitter.com/i/web/status/1228839355491504128\n",
      "Ah, so now Beijing has appointed a virulently anti-Christian, anti-faith party hack to manage #HongKong. This is #China‚Äôs priority - while #coronavirus spreads like wildfire https://t.co/uNeF6GFOgz\n",
      "\n",
      "3. By globaltimesnews at Mon Feb 17 09:18:17 +0000 2020\n",
      "https://twitter.com/i/web/status/1229334238631084032\n",
      "Japan's boy band #ARASHI #Âµê announced on #Weibo their concert scheduled to open in Beijing in April has to be canceled due to #COVID19. They sang a song in Chinese in the video to show their support to China‚Äôs fight against #coronavirus @arashi5official https://t.co/ihVRrVcIVv\n",
      "\n",
      "4. By QuickTake at Sun Feb 16 22:57:12 +0000 2020\n",
      "https://twitter.com/i/web/status/1229177941566902273\n",
      "UPDATE: China's Hubei province reported 1,933 new cases of the #coronavirus, slightly higher than the previous day, and 100 additional deaths.\n",
      "\n",
      "The total number of global infections is nearing 70,000, and the number of fatalities is now at least 1,765 https://t.co/TJkz7CbhCL\n",
      "\n",
      "5. By globaltimesnews at Mon Feb 17 05:09:42 +0000 2020\n",
      "https://twitter.com/i/web/status/1229271683372126209\n",
      "Chinese fans of #BTS member #jhope donate funds originally meant to celebrate the star‚Äôs birthday to charity amid #coronavirus epidemic #JHOPEDay @BTS_twt https://t.co/fAwWi7jOok https://t.co/FX2fJIMHpm\n",
      "\n",
      "6. By ashoswai at Sun Feb 16 15:59:37 +0000 2020\n",
      "https://twitter.com/i/web/status/1229072850906161152\n",
      "National President of All India Hindu Mahasabha says #coronavirus is not a virus but an angry avatar to kiIl all non-vegetarians! There is a competition over buffoonery among Hindutva buffoons.\n",
      "https://t.co/OqGZCXXAKO\n",
      "\n",
      "7. By rachel_cheung1 at Mon Feb 17 07:18:55 +0000 2020\n",
      "https://twitter.com/i/web/status/1229304200217141248\n",
      "A 24-year-old, who travelled from Wuhan to Guangzhou last month, started coughing six days after her 15-day quarantine ended and tested positive for #coronavirus yesterday - yet another case where patients developed symptoms after 14-day incubation period. https://t.co/csCq5LiAsS\n",
      "\n",
      "8. By RT_com at Sun Feb 16 09:40:00 +0000 2020\n",
      "https://twitter.com/i/web/status/1228977316455280640\n",
      "Unexpected February snow in #Wuhan as city remains on lockdown\n",
      "\n",
      "#coronavirus https://t.co/owLhLu4afk\n",
      "\n",
      "9. By BashirAhmaad at Mon Feb 17 09:57:55 +0000 2020\n",
      "https://twitter.com/i/web/status/1229344212770066432\n",
      "PUBLIC ANNOUNCEMENT: Important message for travelers on the epidemic #coronavirus by @FAAN_Official. Kindly watch and retweet for others. https://t.co/xg1unlwybn\n",
      "\n",
      "10. By Gidi_Traffic at Sun Feb 16 19:37:00 +0000 2020\n",
      "https://twitter.com/i/web/status/1229127558081470465\n",
      "\"@jaydboss: I wonder why this is not continuously trending......  #coronavirus @Gidi_Traffic  https://t.co/iqClWpMcGT\n",
      "\n",
      "11. By rhokilpatrick at Sun Feb 16 14:12:41 +0000 2020\n",
      "https://twitter.com/i/web/status/1229045938888441856\n",
      "Report raises questions about Chinese leader's #coronavirus timeline https://t.co/lpJwdkVyYm ‰æÜËá™ @dpa_intl\n",
      "\n",
      "12. By UNICEF at Mon Feb 17 01:05:03 +0000 2020\n",
      "https://twitter.com/i/web/status/1229210113648549888\n",
      "The outbreak of #coronavirus does not justify racial discrimination. Bullying is always wrong.\n",
      "\n",
      "As we work to protect children from #COVID19, we must also protect them from stigma and abuse. Let's be kind, support each other and do our part to #ENDviolence.\n",
      "\n",
      "#VoicesOfYouth https://t.co/SDgreB2CLR\n",
      "\n",
      "13. By UNICEF at Mon Feb 17 05:15:04 +0000 2020\n",
      "https://twitter.com/i/web/status/1229273030871916544\n",
      "üñêÔ∏è Our hands can pass on diseases like #coronavirus even when they may look clean.\n",
      "\n",
      "üëÄ No matter how hard you look, you can‚Äôt see germs with your eyes.\n",
      "\n",
      "üíß Wash your hands thoroughly with soap and clean water to avoid catching #COVID19 and spreading it to the people you love. https://t.co/Dt9tVIAXdJ\n",
      "\n",
      "14. By FCBarcelona at Mon Feb 17 03:16:08 +0000 2020\n",
      "https://twitter.com/i/web/status/1229243101488861186\n",
      "A LOOK BACK | Before the win over Getafe, Bar√ßa showed support for China amid the #coronavirus outbreak https://t.co/PyMtnRArWx\n",
      "\n",
      "15. By joshuawongcf at Mon Feb 17 09:05:48 +0000 2020\n",
      "https://twitter.com/i/web/status/1229331096933978113\n",
      "When thousands of #HKers queued for masks overnight, #HKGov still refused to take measures to stabilize supply and price amid #coronavirus. To combat citywide shortage and price-gouging, @demosisto has just bought another 1,200,000 masks and shipped to #HK. https://t.co/ovNQ3UOJQL\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def lazy_guy_package(query_tag, how_many):\n",
    "    info_keys = [\"full_text\", \"created_at\", ['user','screen_name']]\n",
    "    bearer_token = credentials.bearer_token\n",
    "    search_url_base = \"https://api.twitter.com/1.1/search/tweets.json\"\n",
    "    \n",
    "    tweets = tag_search(bearer_token, search_url_base, query_tag, \"en\", \"popular\", how_many)\n",
    "    \n",
    "    print (\"\\nSearch result:\")\n",
    "    \n",
    "    new_tweets = distill_tweets(tweets, info_keys, True)\n",
    "\n",
    "    return None \n",
    "\n",
    "lazy_guy_package(\"#coronavirus\", 15) \n",
    "# just specify one hashtag, and how many (15) most popular results in the past 7-days you want\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bitb1d790ac39db43d4b1561ff0bd57be33"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
