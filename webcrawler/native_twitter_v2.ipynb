{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Searching Tweets using Twitter's official v2 API in Python \n",
    "Copyleft 2021 Forrest Sheng Bao \n",
    "\n",
    "There are tons of APIs that enable you to search on Twitter, like DocNow's Twarc. But why do you bother them when Twitter has an official Python API? \n",
    "\n",
    "Of course, you can re-invent this API easily, just RESTful-ly query to Twitter server using `request` or `urllib` and then you get a JSON string as the response. \n",
    "\n",
    "## Installation\n",
    "\n",
    "You wanna install from the `v2` branch \n",
    "\n",
    "```shell\n",
    "pip3 install git+https://github.com/twitterdev/search-tweets-python.git@v2\n",
    "```\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First, load the module"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "\n",
    "import searchtweets # twitter official API "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Then, load the search arguments, including tokens from a YAML file \n",
    "\n",
    "The YAML file should be in this format (note the indentation)\n",
    "\n",
    "```yaml\n",
    "search_tweets_v2:\n",
    "    consumer_key = \"a string\"\n",
    "    consumer_secrete = \"a string\"\n",
    "    bearer_token = \"a string\" \n",
    "```\n",
    "\n",
    "The key `search_tweets_v2` allows you to easily switch between different endpoints, e.g., free vs. premium vs. academic. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "search_args = searchtweets.load_credentials(filename=\"credentials.yaml\",\n",
    "                 yaml_key=\"search_tweets_v2\",\n",
    "                 env_overwrite=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Finally, the real game: search\n",
    "\n",
    "There are two ways to search. Here I just show the simpler way which returns a nested JSON string, rather than the fancier way called `ResultStream`. \n",
    "\n",
    "The simpler way is done using [the `collect_results` function, which has only three arguments](https://github.com/twitterdev/search-tweets-python/blob/8883da7f4bea281c7d0df2dc58c1ec5c0fe28e04/searchtweets/result_stream.py#L439): \n",
    "1. the query, which is a dictionary with keys defined [in Twitter API v2 doc here](https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-recent) and values of correponding types. \n",
    "2. max number of Tweets to return \n",
    "3. the search arguments, which was just loaded above from the YAML file.\n",
    "\n",
    "For the argument `query`, a key `query` is mandatory. In the example below, we also set an optional key `tweet.fields`. Specifically, we ask for the language and creation time of tweets in addition. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "\n",
    "query = {\"query\":\"emnlp\", # search emnlp on Twitter\n",
    "         \"tweet.fields\":\"lang,created_at\"} # comma-separated \n",
    "\n",
    "tweets = searchtweets.collect_results(query, \n",
    "                                      max_tweets=10,\n",
    "                                      result_stream_args=search_args)\n",
    "\n",
    "tweets[0][\"data\"][0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'created_at': '2021-12-06T20:15:56.000Z',\n",
       " 'id': '1467950959187968005',\n",
       " 'text': 'Congratulations to Prof. Siva Reddy (@sivareddyg) and his postdoc Edoardo Ponti(@PontiEdoardo) who won the best paper award at EMNLP 2021, for their paper Visually Grounded Reasoning across Languages and Cultures: https://t.co/JDjutIpUS7',\n",
       " 'lang': 'en'}"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, let's see the result. \n",
    "Calling `collect_results` above returns a list of only one element which is a dict\n",
    "of only two keys 'data' and 'meta', the first of which contains tweets matching your query. \n",
    "`tweets[0][\"data\"]` is a list of dictionaries, each of which looks like the print out above.\n",
    "\n",
    "The two default fields in response are `'id'` and `'text'`. The two additional fields `lang` and `created_at` are due to `\"tweet.fields\":\"lang,created_at\"` in our query which askes for the language and creation time of tweets. If you have more fields in the query, you will have correspondingly more fields in the result. \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The end. Just that simple. "
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}