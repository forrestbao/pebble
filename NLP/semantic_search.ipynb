{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic search\n",
    "\n",
    "Copyleft 2022 Forrest Sheng Bao, [a.k.a. Prof. Kung Fun 孔方教授](https://www.youtube.com/c/ForrestBao/videos)\n",
    "\n",
    "Conventional text search (for example, when you press Ctrl+F in your browser) is basically string matching. It is very stupid. For example, if you are a lawyer in China and want to find all cases that your firm has dealt with in the US, you will have to search once in  \"U.S.\", second time in \"United  States\", third time in \"America\", etc. \n",
    "\n",
    "In contrast, semantic search \"understands\" your query and will treat \"U.S.\", \"U.S.A.\", \"America\", and \"United States\" all at once. \n",
    "\n",
    "We will built our semantic search based on [Sentence-BERT](https://www.sbert.net/) (EMNLP 2019) which is trained by forcing the model to learn sentence similarities. \n",
    "\n",
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install -U sentence-transformers\n",
    "# ! pip3 install torch\n",
    "\n",
    "import torch\n",
    "import sentence_transformers # import SentenceTransformer, util\n",
    "import typing\n",
    "\n",
    "embedder = sentence_transformers.SentenceTransformer('all-MiniLM-L6-v2') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then it comes our function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query:str, documents:typing.List[str], number_of_matches = 5):\n",
    "    \"\"\"Search a list of _documents_ against a query\n",
    "    \"\"\"\n",
    "\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "    document_embeddings = embedder.encode(documents, convert_to_tensor=True)\n",
    "    cos_scores = sentence_transformers.util.cos_sim(query_embedding, document_embeddings)[0]\n",
    "    top_matches = torch.topk(cos_scores, k=number_of_matches)\n",
    "    \n",
    "    top_matching_documents = [(documents[idx], score) for score, idx in zip(top_matches[0], top_matches[1]) ]\n",
    "\n",
    "    for document, score in top_matching_documents:\n",
    "        print (document.ljust(80, \"-\"), \" {:.2f}% match\".format(score*100))\n",
    "\n",
    "    return top_matching_documents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's spin!\n",
    "\n",
    "### Demo 1\n",
    "\n",
    "We will search the query \"U.S.A.\" And you will see how the sentences below match up with the query even when \"US\", \"United States\", or \"America\" is not in the sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We defended our clients in the United States.-----------------------------------  39.46% match\n",
      "We helped Alibaba go IPO in the U.S.--------------------------------------------  28.98% match\n",
      "We have offices in California, Delaware, and Iowa.------------------------------  25.40% match\n",
      "We have practiced laws for 20 years in America.---------------------------------  24.19% match\n",
      "Suits is what we wear and our favorite show.------------------------------------  12.52% match\n",
      "We love ramen.------------------------------------------------------------------  11.28% match\n"
     ]
    }
   ],
   "source": [
    "documents = [\n",
    "    \"We helped Alibaba go IPO in the U.S.\",\n",
    "    \"We defended our clients in the United States.\",\n",
    "    \"We have practiced laws for 20 years in America.\", \n",
    "    \"We have offices in California, Delaware, and Iowa.\",\n",
    "    \"We love ramen.\",\n",
    "    \"Suits is what we wear and our favorite show.\"      \n",
    "]\n",
    "\n",
    "query = \"U.S.A.\"\n",
    "\n",
    "_ = semantic_search(query, documents, number_of_matches=len(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A clear cliff can be seen when you move US or US states to \"ramen\" and \"suits\".\n",
    "\n",
    "\n",
    "If we change the query to \"France\", the all sentences have low matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We love ramen.------------------------------------------------------------------  16.16% match\n",
      "We helped Alibaba go IPO in the U.S.--------------------------------------------  13.26% match\n",
      "We have offices in California, Delaware, and Iowa.------------------------------  12.95% match\n",
      "We have practiced laws for 20 years in America.---------------------------------  12.52% match\n",
      "Suits is what we wear and our favorite show.------------------------------------  10.48% match\n",
      "We defended our clients in the United States.-----------------------------------  10.26% match\n"
     ]
    }
   ],
   "source": [
    "_ = semantic_search(\"France\", documents, number_of_matches=len(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo 2\n",
    "\n",
    "Another thing that bothers is spelling variations, e.g., \"email\" vs. \"e-mail\". Conventional search cannot treat the two as the same.  But semantic search can! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I sent you an E-mail.-----------------------------------------------------------  56.72% match\n",
      "We love email over WeChat.------------------------------------------------------  53.48% match\n",
      "I do not get any mail today.----------------------------------------------------  40.75% match\n",
      "In an Open Letter to the citizens, he said no. ---------------------------------  6.82% match\n"
     ]
    }
   ],
   "source": [
    "documents = [\n",
    "    \"We love email over WeChat.\",\n",
    "    \"I sent you an E-mail.\",\n",
    "    \"I do not get any mail today.\",\n",
    "    \"In an Open Letter to the citizens, he said no. \" \n",
    "]\n",
    "\n",
    "query = \"e-mail\"\n",
    "\n",
    "_ = semantic_search(query, documents, number_of_matches=len(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, a clear match score cliff from \"E-mail\" and \"email\" to \"mail\". And the query is \"e-mail\" -- not even in the original text. \n",
    "\n",
    "# How can I use this powerful thing in my company? \n",
    "\n",
    "Want to use the latest NLP technology in your company but have no NLP engineer? \n",
    "Visit http://nlp.llc or email forrest dot bao at gmail dot com and we will help you set it up! \n",
    "\n",
    "NLP, LLC., the power of text understanding in the hands of everyone! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
